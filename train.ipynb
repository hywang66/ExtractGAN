{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from torch.nn import functional as F\n",
    "import torchvision.models\n",
    "from options.train_options import TrainOptions\n",
    "import sys; sys.argv=['']; del sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tb \n",
    "opt = TrainOptions().parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.init_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG parameters loaded.\n"
     ]
    }
   ],
   "source": [
    "def get_pretrained_vgg():\n",
    "    cfg = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
    "\n",
    "    def make_partial_vgg16():\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for v in cfg:\n",
    "            if v == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "                in_channels = v\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def init_vgg16(vgg):\n",
    "        vgg16_state_dict = torchvision.models.vgg16_bn(pretrained=True).state_dict()\n",
    "        dict_new = vgg.state_dict().copy()\n",
    "        new_list = list(vgg.state_dict().keys())\n",
    "        trained_list = list(vgg16_state_dict.keys())\n",
    "        \n",
    "        # for i in range(self.n_vgg_parameters):\n",
    "        for i, _ in enumerate(vgg16.parameters()):\n",
    "            dict_new[new_list[i]] = vgg16_state_dict[trained_list[i]]\n",
    "        \n",
    "        vgg.load_state_dict(dict_new)\n",
    "        print('VGG parameters loaded.')\n",
    "\n",
    "    vgg16 = make_partial_vgg16()\n",
    "    init_vgg16(vgg16)\n",
    "    return vgg16\n",
    "\n",
    "\n",
    "class BaseModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseModule, self).__init__()\n",
    "    \n",
    "    def weights_init_func(self, m, init_type, gain):\n",
    "        if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "            if init_type == 'normal':\n",
    "                init.normal_(m.weight.data, 0.0, gain)\n",
    "            elif init_type == 'xavier':\n",
    "                init.xavier_normal_(m.weight.data, gain=gain)\n",
    "            elif init_type == 'kaiming':\n",
    "                init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "            elif init_type == 'orthogonal':\n",
    "                init.orthogonal_(m.weight.data, gain=gain)\n",
    "            else:\n",
    "                raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                init.constant_(m.bias.data, 0.0)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            init.normal_(m.weight.data, 1.0, gain)\n",
    "            init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "class StyleExtractor(BaseModule):\n",
    "    def __init__(self, vgg=get_pretrained_vgg(), n_kernel_channels=64, \n",
    "                 init_type='xavier', n_hidden=1024):\n",
    "        super(StyleExtractor, self).__init__()\n",
    "\n",
    "        self.nkc = n_kernel_channels\n",
    "        self.vgg16 = vgg\n",
    "        self.representor = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, n_hidden),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            # nn.Linear(4096, 4096),\n",
    "            # nn.ReLU(True),\n",
    "            # nn.Dropout()\n",
    "        )\n",
    "        self.conv_kernel_gen_1 = nn.Linear(n_hidden, n_kernel_channels*n_kernel_channels*3*3)\n",
    "        self.conv_kernel_gen_2 = nn.Linear(n_hidden, n_kernel_channels*n_kernel_channels*3*3)\n",
    "        self.conv_kernel_gen_3 = nn.Linear(n_hidden, n_kernel_channels*n_kernel_channels*3*3)\n",
    "        self.conv_kernel_gen_4 = nn.Linear(n_hidden, n_kernel_channels*n_kernel_channels*3*3)\n",
    "        \n",
    "        weights_init_func = lambda m : self.weights_init_func(m, init_type, gain=0.02)\n",
    "        for module in self.children():\n",
    "            if module is not self.vgg16:\n",
    "                module.apply(weights_init_func)       \n",
    "        print('StyleExtractor weights initialized using %s.' % init_type)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv_kernels = []\n",
    "        features = self.vgg16(x).detach()\n",
    "        deep_features = self.representor(features)\n",
    "        conv_kernels.append(self.conv_kernel_gen_1(deep_features).view(self.nkc, self.nkc, 3, 3))\n",
    "        conv_kernels.append(self.conv_kernel_gen_2(deep_features).view(self.nkc, self.nkc, 3, 3))\n",
    "        conv_kernels.append(self.conv_kernel_gen_3(deep_features).view(self.nkc, self.nkc, 3, 3))\n",
    "        conv_kernels.append(self.conv_kernel_gen_4(deep_features).view(self.nkc, self.nkc, 3, 3))\n",
    "\n",
    "        return conv_kernels\n",
    "                      \n",
    "    def train(self, mode=True):\n",
    "        r\"\"\"\n",
    "        Override the train method inherited from nn.Module to keep vgg blocks always in train mode.\n",
    "        \"\"\"\n",
    "        self.training = mode\n",
    "        for module in self.children():\n",
    "            # if module in self.vgg_block_set:\n",
    "            if module is self.vgg16:\n",
    "                module.train(False)\n",
    "            else:\n",
    "                module.train(mode)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StyleExtractor weights initialized using xavier.\n"
     ]
    }
   ],
   "source": [
    "tnet = StyleExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 8.2833e-02,  2.7968e-02,  7.7096e-02],\n",
       "          [ 4.9341e-02, -3.3441e-02,  1.9572e-02],\n",
       "          [ 8.0300e-02,  7.7076e-02,  8.3349e-02]],\n",
       "\n",
       "         [[-4.4296e-02, -1.7748e-01, -4.8706e-02],\n",
       "          [-1.1003e-01, -2.7530e-01, -1.3474e-01],\n",
       "          [-5.9982e-03, -6.1375e-02,  1.6822e-02]],\n",
       "\n",
       "         [[ 2.7480e-02, -6.6769e-02,  4.3955e-02],\n",
       "          [-2.6662e-02, -1.4995e-01, -3.3615e-02],\n",
       "          [ 5.2778e-02,  1.7143e-02,  8.6744e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.2628e-02,  3.0218e-02, -2.6930e-02],\n",
       "          [-1.3764e-02,  1.1993e-01, -6.6263e-03],\n",
       "          [-2.6019e-02, -8.3535e-03, -3.9197e-02]],\n",
       "\n",
       "         [[-4.0557e-02,  1.3983e-02, -5.4278e-02],\n",
       "          [ 1.5412e-02,  1.8198e-01,  1.7598e-02],\n",
       "          [-1.7032e-02,  1.1284e-02, -2.4226e-02]],\n",
       "\n",
       "         [[-6.5683e-02,  5.9252e-02, -5.3020e-02],\n",
       "          [ 3.8278e-02,  2.7292e-01,  5.9491e-02],\n",
       "          [-4.1218e-02,  3.6159e-02, -3.0478e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.4962e-06, -1.1430e-06,  1.2536e-06],\n",
       "          [-1.0341e-06, -5.1964e-06, -1.1568e-06],\n",
       "          [ 2.5825e-06,  2.5617e-07,  1.6146e-06]],\n",
       "\n",
       "         [[ 3.0030e-06,  4.2831e-07,  2.3388e-06],\n",
       "          [ 2.8718e-07, -3.6006e-06,  1.4238e-07],\n",
       "          [ 2.9393e-06,  8.8762e-07,  2.3288e-06]],\n",
       "\n",
       "         [[ 3.4751e-06,  1.3777e-06,  2.7114e-06],\n",
       "          [ 1.1414e-06, -2.1910e-06,  9.4626e-07],\n",
       "          [ 2.9918e-06,  1.3247e-06,  2.5529e-06]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-7.2593e-03, -2.9968e-03, -6.5453e-03],\n",
       "          [-1.4693e-03,  3.5825e-03, -1.3039e-03],\n",
       "          [-3.8401e-03,  9.9191e-04, -4.4511e-03]],\n",
       "\n",
       "         [[ 8.8825e-03,  1.6103e-02,  1.0071e-02],\n",
       "          [ 1.3242e-02,  2.0966e-02,  1.3489e-02],\n",
       "          [ 3.3097e-03,  9.6999e-03,  2.8076e-03]],\n",
       "\n",
       "         [[-3.5536e-03, -1.2907e-03, -3.8489e-04],\n",
       "          [-3.1573e-03, -1.0735e-03, -6.6944e-04],\n",
       "          [-7.7921e-03, -5.8025e-03, -6.2926e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 6.9319e-07, -1.6391e-07, -5.8921e-07],\n",
       "          [-1.0413e-06, -2.3112e-06, -2.8000e-06],\n",
       "          [-7.2569e-07, -2.0565e-06, -2.1360e-06]],\n",
       "\n",
       "         [[ 2.1572e-06,  1.4367e-06,  4.4553e-07],\n",
       "          [ 7.0185e-07, -4.5378e-07, -1.5195e-06],\n",
       "          [ 6.2624e-07, -6.7885e-07, -1.1442e-06]],\n",
       "\n",
       "         [[-1.2531e-06, -1.3574e-06, -2.2934e-06],\n",
       "          [-1.6023e-06, -2.0898e-06, -3.1680e-06],\n",
       "          [-1.9390e-06, -2.6559e-06, -3.1679e-06]]],\n",
       "\n",
       "\n",
       "        [[[-7.9026e-02, -5.1706e-02, -7.3315e-02],\n",
       "          [-8.8093e-02, -4.9941e-02, -5.7828e-02],\n",
       "          [-8.6714e-02, -5.7272e-02, -6.3606e-02]],\n",
       "\n",
       "         [[ 1.3644e-01,  3.2008e-01,  1.9282e-01],\n",
       "          [ 2.5841e-01,  4.7524e-01,  3.3955e-01],\n",
       "          [ 1.1912e-01,  2.9530e-01,  1.8259e-01]],\n",
       "\n",
       "         [[-6.7480e-02, -1.1041e-01, -9.0524e-02],\n",
       "          [-1.4039e-01, -1.9100e-01, -1.6377e-01],\n",
       "          [-1.2401e-01, -1.7676e-01, -1.5988e-01]]]], requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tnet.vgg16.parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder weights initialized using xavier.\n",
      "Decoder weights initialized using xavier.\n",
      "VGG parameters loaded.\n",
      "StyleExtractor weights initialized using xavier.\n",
      "StyleWhitener weights initialized using xavier.\n",
      "Generator build success!\n"
     ]
    }
   ],
   "source": [
    "tnet = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tnet.style_extractor.children())[0] is tnet.style_extractor.vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_vgg():\n",
    "    cfg = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
    "\n",
    "    def make_partial_vgg16():\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for v in cfg:\n",
    "            if v == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "                in_channels = v\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def init_vgg16(vgg):\n",
    "        vgg16_state_dict = torchvision.models.vgg16_bn(pretrained=True).state_dict()\n",
    "        dict_new = vgg.state_dict().copy()\n",
    "        new_list = list(vgg.state_dict().keys())\n",
    "        trained_list = list(vgg16_state_dict.keys())\n",
    "        \n",
    "        # for i in range(self.n_vgg_parameters):\n",
    "        for i, _ in enumerate(vgg16.parameters()):\n",
    "            dict_new[new_list[i]] = vgg16_state_dict[trained_list[i]]\n",
    "        \n",
    "        vgg.load_state_dict(dict_new)\n",
    "        print('VGG parameters loaded.')\n",
    "\n",
    "    vgg16 = make_partial_vgg16()\n",
    "    init_vgg16(vgg16)\n",
    "    return vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG parameters loaded.\n"
     ]
    }
   ],
   "source": [
    "vgg16 = get_pretrained_vgg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace)\n",
      "  (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (5): ReLU(inplace)\n",
      "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (9): ReLU(inplace)\n",
      "  (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): ReLU(inplace)\n",
      "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (16): ReLU(inplace)\n",
      "  (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (19): ReLU(inplace)\n",
      "  (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (22): ReLU(inplace)\n",
      "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (26): ReLU(inplace)\n",
      "  (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (29): ReLU(inplace)\n",
      "  (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (32): ReLU(inplace)\n",
      "  (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (36): ReLU(inplace)\n",
      "  (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (39): ReLU(inplace)\n",
      "  (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (42): ReLU(inplace)\n",
      "  (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_real = torchvision.models.vgg16_bn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 8.2833e-02,  2.7968e-02,  7.7096e-02],\n",
       "          [ 4.9341e-02, -3.3441e-02,  1.9572e-02],\n",
       "          [ 8.0300e-02,  7.7076e-02,  8.3349e-02]],\n",
       "\n",
       "         [[-4.4296e-02, -1.7748e-01, -4.8706e-02],\n",
       "          [-1.1003e-01, -2.7530e-01, -1.3474e-01],\n",
       "          [-5.9982e-03, -6.1375e-02,  1.6822e-02]],\n",
       "\n",
       "         [[ 2.7480e-02, -6.6769e-02,  4.3955e-02],\n",
       "          [-2.6662e-02, -1.4995e-01, -3.3615e-02],\n",
       "          [ 5.2778e-02,  1.7143e-02,  8.6744e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.2628e-02,  3.0218e-02, -2.6930e-02],\n",
       "          [-1.3764e-02,  1.1993e-01, -6.6263e-03],\n",
       "          [-2.6019e-02, -8.3535e-03, -3.9197e-02]],\n",
       "\n",
       "         [[-4.0557e-02,  1.3983e-02, -5.4278e-02],\n",
       "          [ 1.5412e-02,  1.8198e-01,  1.7598e-02],\n",
       "          [-1.7032e-02,  1.1284e-02, -2.4226e-02]],\n",
       "\n",
       "         [[-6.5683e-02,  5.9252e-02, -5.3020e-02],\n",
       "          [ 3.8278e-02,  2.7292e-01,  5.9491e-02],\n",
       "          [-4.1218e-02,  3.6159e-02, -3.0478e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.4962e-06, -1.1430e-06,  1.2536e-06],\n",
       "          [-1.0341e-06, -5.1964e-06, -1.1568e-06],\n",
       "          [ 2.5825e-06,  2.5617e-07,  1.6146e-06]],\n",
       "\n",
       "         [[ 3.0030e-06,  4.2831e-07,  2.3388e-06],\n",
       "          [ 2.8718e-07, -3.6006e-06,  1.4238e-07],\n",
       "          [ 2.9393e-06,  8.8762e-07,  2.3288e-06]],\n",
       "\n",
       "         [[ 3.4751e-06,  1.3777e-06,  2.7114e-06],\n",
       "          [ 1.1414e-06, -2.1910e-06,  9.4626e-07],\n",
       "          [ 2.9918e-06,  1.3247e-06,  2.5529e-06]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-7.2593e-03, -2.9968e-03, -6.5453e-03],\n",
       "          [-1.4693e-03,  3.5825e-03, -1.3039e-03],\n",
       "          [-3.8401e-03,  9.9191e-04, -4.4511e-03]],\n",
       "\n",
       "         [[ 8.8825e-03,  1.6103e-02,  1.0071e-02],\n",
       "          [ 1.3242e-02,  2.0966e-02,  1.3489e-02],\n",
       "          [ 3.3097e-03,  9.6999e-03,  2.8076e-03]],\n",
       "\n",
       "         [[-3.5536e-03, -1.2907e-03, -3.8489e-04],\n",
       "          [-3.1573e-03, -1.0735e-03, -6.6944e-04],\n",
       "          [-7.7921e-03, -5.8025e-03, -6.2926e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 6.9319e-07, -1.6391e-07, -5.8921e-07],\n",
       "          [-1.0413e-06, -2.3112e-06, -2.8000e-06],\n",
       "          [-7.2569e-07, -2.0565e-06, -2.1360e-06]],\n",
       "\n",
       "         [[ 2.1572e-06,  1.4367e-06,  4.4553e-07],\n",
       "          [ 7.0185e-07, -4.5378e-07, -1.5195e-06],\n",
       "          [ 6.2624e-07, -6.7885e-07, -1.1442e-06]],\n",
       "\n",
       "         [[-1.2531e-06, -1.3574e-06, -2.2934e-06],\n",
       "          [-1.6023e-06, -2.0898e-06, -3.1680e-06],\n",
       "          [-1.9390e-06, -2.6559e-06, -3.1679e-06]]],\n",
       "\n",
       "\n",
       "        [[[-7.9026e-02, -5.1706e-02, -7.3315e-02],\n",
       "          [-8.8093e-02, -4.9941e-02, -5.7828e-02],\n",
       "          [-8.6714e-02, -5.7272e-02, -6.3606e-02]],\n",
       "\n",
       "         [[ 1.3644e-01,  3.2008e-01,  1.9282e-01],\n",
       "          [ 2.5841e-01,  4.7524e-01,  3.3955e-01],\n",
       "          [ 1.1912e-01,  2.9530e-01,  1.8259e-01]],\n",
       "\n",
       "         [[-6.7480e-02, -1.1041e-01, -9.0524e-02],\n",
       "          [-1.4039e-01, -1.9100e-01, -1.6377e-01],\n",
       "          [-1.2401e-01, -1.7676e-01, -1.5988e-01]]]], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vgg_real.parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 8.2833e-02,  2.7968e-02,  7.7096e-02],\n",
       "          [ 4.9341e-02, -3.3441e-02,  1.9572e-02],\n",
       "          [ 8.0300e-02,  7.7076e-02,  8.3349e-02]],\n",
       "\n",
       "         [[-4.4296e-02, -1.7748e-01, -4.8706e-02],\n",
       "          [-1.1003e-01, -2.7530e-01, -1.3474e-01],\n",
       "          [-5.9982e-03, -6.1375e-02,  1.6822e-02]],\n",
       "\n",
       "         [[ 2.7480e-02, -6.6769e-02,  4.3955e-02],\n",
       "          [-2.6662e-02, -1.4995e-01, -3.3615e-02],\n",
       "          [ 5.2778e-02,  1.7143e-02,  8.6744e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.2628e-02,  3.0218e-02, -2.6930e-02],\n",
       "          [-1.3764e-02,  1.1993e-01, -6.6263e-03],\n",
       "          [-2.6019e-02, -8.3535e-03, -3.9197e-02]],\n",
       "\n",
       "         [[-4.0557e-02,  1.3983e-02, -5.4278e-02],\n",
       "          [ 1.5412e-02,  1.8198e-01,  1.7598e-02],\n",
       "          [-1.7032e-02,  1.1284e-02, -2.4226e-02]],\n",
       "\n",
       "         [[-6.5683e-02,  5.9252e-02, -5.3020e-02],\n",
       "          [ 3.8278e-02,  2.7292e-01,  5.9491e-02],\n",
       "          [-4.1218e-02,  3.6159e-02, -3.0478e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.4962e-06, -1.1430e-06,  1.2536e-06],\n",
       "          [-1.0341e-06, -5.1964e-06, -1.1568e-06],\n",
       "          [ 2.5825e-06,  2.5617e-07,  1.6146e-06]],\n",
       "\n",
       "         [[ 3.0030e-06,  4.2831e-07,  2.3388e-06],\n",
       "          [ 2.8718e-07, -3.6006e-06,  1.4238e-07],\n",
       "          [ 2.9393e-06,  8.8762e-07,  2.3288e-06]],\n",
       "\n",
       "         [[ 3.4751e-06,  1.3777e-06,  2.7114e-06],\n",
       "          [ 1.1414e-06, -2.1910e-06,  9.4626e-07],\n",
       "          [ 2.9918e-06,  1.3247e-06,  2.5529e-06]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-7.2593e-03, -2.9968e-03, -6.5453e-03],\n",
       "          [-1.4693e-03,  3.5825e-03, -1.3039e-03],\n",
       "          [-3.8401e-03,  9.9191e-04, -4.4511e-03]],\n",
       "\n",
       "         [[ 8.8825e-03,  1.6103e-02,  1.0071e-02],\n",
       "          [ 1.3242e-02,  2.0966e-02,  1.3489e-02],\n",
       "          [ 3.3097e-03,  9.6999e-03,  2.8076e-03]],\n",
       "\n",
       "         [[-3.5536e-03, -1.2907e-03, -3.8489e-04],\n",
       "          [-3.1573e-03, -1.0735e-03, -6.6944e-04],\n",
       "          [-7.7921e-03, -5.8025e-03, -6.2926e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 6.9319e-07, -1.6391e-07, -5.8921e-07],\n",
       "          [-1.0413e-06, -2.3112e-06, -2.8000e-06],\n",
       "          [-7.2569e-07, -2.0565e-06, -2.1360e-06]],\n",
       "\n",
       "         [[ 2.1572e-06,  1.4367e-06,  4.4553e-07],\n",
       "          [ 7.0185e-07, -4.5378e-07, -1.5195e-06],\n",
       "          [ 6.2624e-07, -6.7885e-07, -1.1442e-06]],\n",
       "\n",
       "         [[-1.2531e-06, -1.3574e-06, -2.2934e-06],\n",
       "          [-1.6023e-06, -2.0898e-06, -3.1680e-06],\n",
       "          [-1.9390e-06, -2.6559e-06, -3.1679e-06]]],\n",
       "\n",
       "\n",
       "        [[[-7.9026e-02, -5.1706e-02, -7.3315e-02],\n",
       "          [-8.8093e-02, -4.9941e-02, -5.7828e-02],\n",
       "          [-8.6714e-02, -5.7272e-02, -6.3606e-02]],\n",
       "\n",
       "         [[ 1.3644e-01,  3.2008e-01,  1.9282e-01],\n",
       "          [ 2.5841e-01,  4.7524e-01,  3.3955e-01],\n",
       "          [ 1.1912e-01,  2.9530e-01,  1.8259e-01]],\n",
       "\n",
       "         [[-6.7480e-02, -1.1041e-01, -9.0524e-02],\n",
       "          [-1.4039e-01, -1.9100e-01, -1.6377e-01],\n",
       "          [-1.2401e-01, -1.7676e-01, -1.5988e-01]]]], requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vgg16.parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor(2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-226979659555413959137820672.0000,                            0.0000,\n",
       "                                     0.0000,                            0.0000],\n",
       "         [                           0.0000,                            0.0000,\n",
       "                                     0.0000,                            0.0000],\n",
       "         [                           0.0000,                            0.0000,\n",
       "                                     0.0000,                            0.0000]],\n",
       "\n",
       "        [[                           0.0000,                            0.0000,\n",
       "                                     0.0000,                            0.0000],\n",
       "         [                           0.0000,                            0.0000,\n",
       "                                     0.0000,                            0.0000],\n",
       "         [                           0.0000,                            0.0000,\n",
       "                                     0.0000,                            0.0000]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 13])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor(2,6)\n",
    "b = torch.Tensor(2,7)\n",
    "torch.cat((a,b), 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG parameters loaded.\n"
     ]
    }
   ],
   "source": [
    "class Discriminator(BaseModule):\n",
    "    def __init__(self, vgg=get_pretrained_vgg(), \n",
    "                 init_type='xavier', n_hidden=1024):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.vgg16 = vgg\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7 * 2, n_hidden),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(n_hidden, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        \n",
    "        weights_init_func = lambda m : self.weights_init_func(m, init_type, gain=0.02)\n",
    "        for module in self.children():\n",
    "            if module is not self.vgg16:\n",
    "                module.apply(weights_init_func)       \n",
    "        print('Discriminator weights initialized using %s.' % init_type)\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        feature1 = self.vgg16(img1).detach().view(img1.size(0), -1)\n",
    "        feature2 = self.vgg16(img2).detach().view(img1.size(0), -1)\n",
    "        feature_cat = torch.cat((feature1, feature2), 1)\n",
    "        prob = self.classifier(feature_cat)\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator weights initialized using xavier.\n"
     ]
    }
   ],
   "source": [
    "a = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
